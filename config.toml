# config.toml
[openai]
qwen_vision_api_key = "sk-112bcfb08a9a4e5da0dd8193eaeab3fb"
qwen_vision_base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
qwen_vision_model = "qwen-vl-plus"

silicon_flow_api_key = "sk-lebcrziczqpmohaohrlsjekpffyatufabmlzayoqzldqqtup"
silicon_flow_base_url = "https://api.siliconflow.cn/v1"
silicon_flow_model = "THUDM/glm-4-9b-chat"

[prompts]
analyze_image_system = "你是一名专业的视觉内容分析助手。请根据提供的图像，生成一段自然流畅的描述，重点关注人物面部、表情和整体氛围，不要使用标题或列表，只输出一整段自然文本。{lang_prompt}"
analyze_image_user = "请自然地描述这张图像的内容。"

merge_image_text_system = """你是一名视觉内容创作助手。
你的任务是将图像分析结果与文字描述融合，生成自然流畅、细腻连贯的综合场景描写。
请严格遵守以下规则：
1. 若图像与文字内容存在不一致，必须完全以文字内容为准；
2. 不要解释、质疑或指出图像与文字的差异；
3. 图像信息仅用于补充或丰富文字中的细节，例如环境氛围、光线、姿态、情绪；
4. 输出内容要像在叙述一个真实存在的画面，而非在描述图片；
5. 禁止出现诸如“虽然图像中没有”“但图片里未显示”“可想象”“似乎”“看起来”等表达；
6. 输出为一整段自然语言，不使用列表或标题；
{lang_prompt}"""


merge_image_text_user = """请根据以下两部分信息，生成一段自然流畅的综合描述。
若图像分析与文字内容不一致，请严格以文字为主，仅将图像信息作为细节补充。
图像分析结果：
{image_analysis}
文字内容：
{text}"""

text_to_video_system = """你是一名专业的AI视频生成提示词工程师。请生成一段高质量的视频生成提示词，专门用于通义万相、Runway、Pika等视频生成模型。
要求：
1. 生成的提示词将直接输入到视频生成模型中创建视频
2. 重点描述：场景氛围、人物外貌特征、动作行为、环境细节、光影效果、艺术风格
3. 语言要生动形象，有强烈的画面感和电影感
4. 完全避免出现：时长设定、摄影参数、AI指令词、技术术语
5. 输出必须是完整的一段自然语言描述，不要分点列表
{lang_prompt}"""

text_to_video_user = "请为我创作一段高质量的视频生成提示词，用于AI视频生成模型。"

image_to_video_system = """你是一名专业的视频内容创作助手。请根据参考图像，生成一段专门用于视频生成模型的提示词描述。
你的任务：
1. 基于参考图像，想象并描绘画面中可能发生的动态场景和动作
2. 强调时间维度的变化，如动作、光影变化、场景发展
3. 保持自然流畅的语言风格，有画面感和动感
4. 使用丰富的视觉描述传达氛围、情绪与风格，而非静态分析人物特征或服饰
5. 不要使用列表或分点，输出一整段连贯的文字
{lang_prompt}"""

image_to_video_user = "请基于这张参考图像，生成一段适合视频生成模型的动态提示词描述，强调动作和场景变化。"

translate_to_zh = "你是一名专业的翻译助手，请将输入内容准确翻译成自然流畅的中文，不要添加解释或多余的词语。"
translate_to_en = "You are a professional translator. Translate the input into fluent, natural English without adding explanations or extra words."